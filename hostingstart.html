<!DOCTYPE html>
<html>
<head>
	<meta name="viewport" content="width=device-width, initial-scale=0.5">
	<title>Face Recognition</title>
	
<!--	<script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.0.0.js"></script>	
-->	<script type="text/javascript" src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-2.1.4.js"></script>
	<script>

		// Put event listeners into place
		window.addEventListener("DOMContentLoaded", function() {
			// Grab elements, create settings, etc.
			var canvas = document.getElementById("canvas"),
				context = canvas.getContext("2d"),
				video = document.getElementById("video"),
				videoObj = { "video": true, "audio": false },
				errBack = function(error) {
					console.log("Video capture error: ", error.code); 
				};

			// Put video listeners into place
			if(navigator.getUserMedia) { // Standard
				navigator.getUserMedia(videoObj, function(stream) {
					video.src = stream;
					video.play();
				}, errBack);
			} else if(navigator.webkitGetUserMedia) { // WebKit-prefixed
				navigator.webkitGetUserMedia(videoObj, function(stream){
					video.src = window.webkitURL.createObjectURL(stream);
					video.play();
				}, errBack);
			} else if(navigator.mozGetUserMedia) { // WebKit-prefixed
				navigator.mozGetUserMedia(videoObj, function(stream){
					video.src = window.URL.createObjectURL(stream);
					video.play();
				}, errBack);
			}
		
			// Trigger photo take
			document.getElementById("snap").addEventListener("click", function() {
				context.drawImage(video, 0, 0, 640, 480);	
				pngHolder = document.getElementById("pngHolder")
				pngimage = document.getElementById("pngimage")				

//				var image = convertCanvasToImage(canvas);
//				pngHolder.replaceChild( image , pngimage );
				var binaryData = dataURItoBlob( canvas.toDataURL("image/png") );
				
				// Detect faces on the image calling the FACE API
				var faceID = detect(binaryData);
				console.log(faceID);
				var confidence = findsimilars(faceID);
				console.log(confidence);
				logintest(0.8,confidence);	// Seuil de confiance à 80% de match
				
			}, false);
			
			// Converts canvas to an image
			function convertCanvasToImage(canvas) {
				var image = new Image();
				image.src = canvas.toDataURL("image/png");
				image.id = "pngimage";
				return image;
			}

			function logintest(level,confidence) {
				if( confidence > level) {
					document.getElementById("confidence").innerHTML = ("Accès autorisé (confiance : " + (confidence * 100) + "%)");
				} else {
					document.getElementById("confidence").innerHTML = ("Accès refusé (confiance : " + (confidence * 100) + "%)");
				}
			}
			
			// Detect faces on the image calling the FACE API
			function detect(binaryData){
				var faceID = true;
				$.ajax({		
					url: 'https://api.projectoxford.ai/face/v1.0/detect?returnFaceAttributes=age,gender',
					type: 'POST',
					dataType: 'JSON',
					headers: {
//						'Content-Type':'application/json',
						'Content-Type':'application/octet-stream',
						'Ocp-Apim-Subscription-Key':'ce2a8c99da534c629db74e0918bc2861'
					},			
//					data: JSON.stringify( { "url": "https://facerecognitionaleki.azurewebsites.net/faces/aleki1.png" } ),
					data: binaryData,
					processData: false,
					async: false,
					error: function( errorThrown ){
						console.log( errorThrown );
						return errorThrown;
					},
					success: function( data ){
						console.log( JSON.stringify( data ) );	
						data.forEach(function(face){
					//		console.log( face.faceAttributes.gender);
					//		console.log( face.faceAttributes.age);
					//		console.log( face.faceId);
							faceID = face.faceId;
						});
					}
				});
				return faceID;
			}

			// Find similarities to authorize access
			function findsimilars(faceID) {
				var confidence = false;
				$.ajax({		
					url: 'https://api.projectoxford.ai/face/v1.0/findsimilars',
					type: 'POST',
					dataType: 'JSON',
					headers: {
						'Content-Type':'application/json',
						'Ocp-Apim-Subscription-Key':'ce2a8c99da534c629db74e0918bc2861'
					},			
					data: JSON.stringify( { 'faceId': faceID , 'faceListId':'authorized', 'maxNumOfCandidatesReturned':1 } ),
					processData: false,
					async: false,
					error: function( errorThrown ){
						console.log( errorThrown );
						return errorThrown;
					},
					success: function( data ){
						console.log( JSON.stringify( data ) );	
						data.forEach(function(face){
					//		console.log(face.confidence);
							confidence = face.confidence;
						});
					}
				});
				return confidence
			}	
				
			function dataURItoBlob(dataURI) {
			  // convert base64 to raw binary data held in a string
			  // doesn't handle URLEncoded DataURIs - see SO answer #6850276 for code that does this
			  var byteString = atob(dataURI.split(',')[1]);

			  // separate out the mime component
			  var mimeString = dataURI.split(',')[0].split(':')[1].split(';')[0]

			  // write the bytes of the string to an ArrayBuffer
			  var ab = new ArrayBuffer(byteString.length);
			  var ia = new Uint8Array(ab);
			  for (var i = 0; i < byteString.length; i++) {
				  ia[i] = byteString.charCodeAt(i);
			  }

			  // write the ArrayBuffer to a blob, and you're done
			  var blob = new Blob([ab], {type: mimeString});
			  return blob;
			}
			
		}, false);

	</script>
	   
	<script>                
		jQuery(function($){
			console.log("jQuery est prêt !");
		});
    </script>
	
</head>	
<body>
<!--
	Ideally these elements aren't created until it's confirmed that the 
	client supports video/camera, but for the sake of illustrating the 
	elements involved, they are created with markup (not JavaScript)
-->
	<video id="video" width="640" height="480" autoplay></video>
	<button id="snap" class="sexyButton">Login</button>
	<canvas id="canvas" width="640" height="480" style="display:none;"></canvas>
	<p id="confidence"></p>

</body>
</html>